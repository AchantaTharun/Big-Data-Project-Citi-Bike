{"cells": [{"cell_type": "markdown", "id": "47d629e6-ea87-4936-a699-368413ce127d", "metadata": {}, "source": "# Importing libraries and initializing spark session"}, {"cell_type": "markdown", "id": "63d46963-99dd-4c5a-8044-5a8d3205c980", "metadata": {"tags": []}, "source": "### Creating spark session and reading data from previous pipeline"}, {"cell_type": "code", "execution_count": 20, "id": "1fea328e-a3d1-4a6e-a999-f7f597eab90b", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline\nimport os\n\nspark =( SparkSession.builder\n    .appName(\"Models\")\n    .config(\"spark.executor.instances\",\"3\")\n    .config(\"spark.executor.memory\",\"8g\")\n    .config(\"spark.sql.shuffle.partitions\", 20)\n    .getOrCreate())\n\n\ntrain = \"gs://newbucketforabhishek/pipeline2_train_data.parquet_part-00000-cae65e05-711e-4164-b976-9bbecbe426e8-c000.snappy.parquet\"\ntest = \"gs://newbucketforabhishek/pipeline2_test_data.parquet_part-00000-cee56338-7d78-490c-93da-5eb185bd7b3e-c000.snappy.parquet\""}, {"cell_type": "markdown", "id": "88fa61d4-a145-4bb0-ba29-62e3eee491a3", "metadata": {}, "source": "# Reading citibike combined data"}, {"cell_type": "markdown", "id": "60d2a9a7-1147-4651-ba5e-7f514f21b207", "metadata": {}, "source": "### Efficient Parallelism:\n\n### 80 partitions for training data distribute the workload evenly across 20 cores.\n### 40 partitions for testing data minimize task scheduling overhead."}, {"cell_type": "code", "execution_count": 24, "id": "2827c6f6-f7e3-4224-af23-0416fe609108", "metadata": {"tags": []}, "outputs": [], "source": "\ntrain_data = spark.read.parquet(train)\ntest_data = spark.read.parquet(test)\ntrain_data = train_data.repartition(20)\ntest_data = test_data.repartition(20)"}, {"cell_type": "code", "execution_count": 10, "id": "a6b0e3cf-f7d7-4dbc-80ca-7a05399500a0", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 4:=======================================>                 (14 + 6) / 20]\r"}], "source": "feature_cols = [\"day_of_week\", \"month\", \"hour\", \"year\", \"temp\", \"humidity\", \n                \"precip\",  \"windspeed\", \"visibility\", \n                 \"is_weekend\", \"is_lockdown\",\"startstationname_indexed\", \"humidity_is_weekend\", \"temp_is_weekend\",\"hour_bucket_indexed\", \"rolling_avg_demand\", \"lag_demand_1\" ]"}, {"cell_type": "markdown", "id": "2e806e97-d10e-45a0-b3fd-0c8a97cff4b7", "metadata": {}, "source": "* `VectorAssembler`\nCombines multiple input features into a single vector column (features), required for ML models.\n* `StandardScaler`\nStandardizes the feature vector by removing the mean and scaling to unit variance."}, {"cell_type": "code", "execution_count": 11, "id": "6b392099-350a-4454-9d1a-c11d29d1246a", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml import Pipeline\n\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n"}, {"cell_type": "code", "execution_count": 12, "id": "d04e719a-3d86-43df-881c-565e78d946c6", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 4:================================================>        (17 + 3) / 20]\r"}], "source": "from pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml.tuning import TrainValidationSplit\n\ndt = DecisionTreeRegressor(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\n#pipeline\npipeline = Pipeline(stages=[assembler, scaler, dt])"}, {"cell_type": "markdown", "id": "618bb6c1-f5ca-4fcc-950d-05dd2be284db", "metadata": {"tags": []}, "source": "### Hyperparameter Tuning with `TrainValidationSplit`\n\nTo optimize the performance of the Decision Tree Regressor, we implemented hyperparameter tuning using `TrainValidationSplit`.\n\n#### **1. Define the Parameter Grid**\nWe specify the hyperparameters to tune:\n- **`maxDepth`:** Maximum depth of the tree (values: 3, 5).\n- **`minInstancesPerNode`:** Minimum number of samples per tree node (values: 1, 2).\n- **`maxBins`:** Number of bins for continuous feature discretization (values: 16, 32).\n\n"}, {"cell_type": "code", "execution_count": 13, "id": "f3e837df-e1f0-44e7-857e-abb89fabf380", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/21 19:58:47 WARN CacheManager: Asked to cache already cached data.\n"}, {"data": {"text/plain": "DataFrame[date: date, day_of_week: int, month: int, hour: int, year: int, startstationname: string, demand: bigint, datetime: timestamp, temp: double, humidity: double, precip: double, windspeed: double, visibility: double, conditions: string, is_weekend: int, is_lockdown: int, conditions_indexed: double, startstationname_indexed: double, lag_demand_1: bigint, rolling_avg_demand: double, hour_bucket: string, hour_bucket_indexed: double, temp_is_weekend: double, humidity_is_weekend: double]"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "train_data.cache()"}, {"cell_type": "code", "execution_count": 15, "id": "2a8057de-c384-4955-9107-0fdb2aaf734b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 324:=================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Root Mean Squared Error (RMSE): 2.3258849854856116\nR-Squared (R2): 0.726728053874677\nMean Absolute Error (MAE): 1.5019751713865255\nMean Squared Error (MSE): 5.409740965707404\nCPU times: user 711 ms, sys: 158 ms, total: 869 ms\nWall time: 9min 8s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nparam_grid = (ParamGridBuilder()\n              .addGrid(dt.maxDepth, [3, 5])  \n              .addGrid(dt.minInstancesPerNode, [1, 2]) \n              .addGrid(dt.maxBins, [16])\n              .build())\nevaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\n\ntrain_val_split = TrainValidationSplit(estimator=pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=evaluator,\n                                       trainRatio=0.8)\n\n\n# Fit the model\ntv_model = train_val_split.fit(train_data)\n\n# Best model and predictions\nbest_model = tv_model.bestModel\npredictions = best_model.transform(test_data)\n\n\n# Evaluate RMSE\nrmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = rmse_evaluator.evaluate(predictions)\n\n# Evaluate R2\nr2_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\")\nr2 = r2_evaluator.evaluate(predictions)\n\n# # Evaluate Mean Absolute Error (MAE)\nmae_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\")\nmae = mae_evaluator.evaluate(predictions)\n\n# Evaluate Mean Squared Error (MSE)\nmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\nmse = mse_evaluator.evaluate(predictions)\n\n# Print all metrics\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-Squared (R2): {r2}\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\n"}, {"cell_type": "code", "execution_count": 21, "id": "eb3a492b-55d6-435c-a310-e2a6766e5b26", "metadata": {"tags": []}, "outputs": [], "source": "\ntrain_data = spark.read.parquet(train)\ntest_data = spark.read.parquet(test)\ntrain_data = train_data.repartition(20)\ntest_data = test_data.repartition(20)\ntrain_data = train_data.sample(withReplacement=False, fraction=0.8)\ntest_data = test_data.sample(withReplacement=False, fraction=0.8)\n"}, {"cell_type": "code", "execution_count": 22, "id": "c65a30cb-2312-4a42-8998-bb5b2c197f96", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 599:=================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Root Mean Squared Error (RMSE): 2.3176595142714795\nR-Squared (R2): 0.7284985001214339\nMean Absolute Error (MAE): 1.4939340854071734\nMean Squared Error (MSE): 5.37154562409311\nCPU times: user 658 ms, sys: 149 ms, total: 808 ms\nWall time: 8min 1s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nparam_grid = (ParamGridBuilder()\n              .addGrid(dt.maxDepth, [3, 5])  \n              .addGrid(dt.minInstancesPerNode, [1, 2]) \n              .addGrid(dt.maxBins, [16])\n              .build())\nevaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\ntrain_val_split = TrainValidationSplit(estimator=pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=evaluator,\n                                       trainRatio=0.8)\n\n\n# Fit the model\ntv_model = train_val_split.fit(train_data)\n\n# Best model and predictions\nbest_model = tv_model.bestModel\npredictions = best_model.transform(test_data)\n\n\n# Evaluate RMSE\nrmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = rmse_evaluator.evaluate(predictions)\n\n# Evaluate R2\nr2_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\")\nr2 = r2_evaluator.evaluate(predictions)\n\n# # Evaluate Mean Absolute Error (MAE)\nmae_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\")\nmae = mae_evaluator.evaluate(predictions)\n\n# Evaluate Mean Squared Error (MSE)\nmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\nmse = mse_evaluator.evaluate(predictions)\n\n# Print all metrics\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"R-Squared (R2): {r2}\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")"}, {"cell_type": "code", "execution_count": 9, "id": "98a2bc27-669d-4ef3-8b75-223ae06c94b5", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#predictions.write.mode(\"overwrite\").parquet(\"gs://bucket121024/pipeline3/5_DT.parquet\")"}, {"cell_type": "markdown", "id": "5f3432f4-eba6-48e1-9f9d-beb540129455", "metadata": {"tags": []}, "source": "# Random Forest Regressor\n## Hyperparameter Tuning with `ParamGridBuilder`\n\nThe `ParamGridBuilder` is used to define a grid of hyperparameters for tuning the Random Forest Regressor. In this case:\n\n### Explanation of Parameters:\n1. **`numTrees`**:\n   - The number of decision trees in the Random Forest.\n   - Tested values: `50`, `100`.\n\n2. **`maxDepth`**:\n   - The maximum depth of each tree, which controls the complexity of the model.\n   - Tested values: `5`, `10`.\n\n### Total Combinations:\nThe total combinations of hyperparameters are:\n\\[\n\\text{Total Combinations} = \\text{len(numTrees)} \\times \\text{len(maxDepth)} = 2 \\times 2 = 4\n\\]\n\nEach combination is evaluated during training to select the best-performing model based on validation metrics.\n"}, {"cell_type": "code", "execution_count": 23, "id": "a0edd3e4-442b-4cca-867a-334d8742d34a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "WARNING: An illegal reflective access operation has occurred                    \nWARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.1.jar) to field java.nio.charset.Charset.name\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n24/12/21 21:03:23 WARN DAGScheduler: Broadcasting large task binary with size 1239.5 KiB\n24/12/21 21:05:20 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n24/12/21 21:07:28 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/21 21:10:28 WARN DAGScheduler: Broadcasting large task binary with size 1230.9 KiB\n24/12/21 21:10:30 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n24/12/21 21:13:50 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n24/12/21 21:33:43 WARN DAGScheduler: Broadcasting large task binary with size 1228.3 KiB\n24/12/21 21:37:28 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n24/12/21 21:41:48 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/21 21:47:30 WARN DAGScheduler: Broadcasting large task binary with size 1237.3 KiB\n24/12/21 21:47:32 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n24/12/21 21:54:27 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n24/12/21 21:54:31 WARN DAGScheduler: Broadcasting large task binary with size 15.7 MiB\n24/12/21 22:02:31 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n24/12/21 22:15:59 WARN DAGScheduler: Broadcasting large task binary with size 1216.0 KiB\n24/12/21 22:20:13 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n24/12/21 22:25:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n24/12/21 22:31:57 WARN DAGScheduler: Broadcasting large task binary with size 1237.9 KiB\n24/12/21 22:31:59 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n24/12/21 22:40:24 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n24/12/21 22:40:29 WARN DAGScheduler: Broadcasting large task binary with size 15.7 MiB\n24/12/21 22:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.7 MiB\n[Stage 811:====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Random Forest Regressor - RMSE: 2.1096479372849815\nRandom Forest Regressor - R2: 0.7750464066061753\nRandom Forest Regressor - MAE: 1.3746830139552535\nRandom Forest Regressor - MSE: 4.450614419290777\nCPU times: user 2.17 s, sys: 523 ms, total: 2.69 s\nWall time: 2h 3min 55s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nfrom pyspark.ml.regression import RandomForestRegressor\n\n# Initialize Random Forest Regressor\nrf = RandomForestRegressor(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\n# Create a pipeline\nrf_pipeline = Pipeline(stages=[assembler, scaler, rf])\n\n# Define hyperparameter grid\nparam_grid = (ParamGridBuilder()\n              .addGrid(rf.numTrees, [50, 100])  # Tune number of trees\n              .addGrid(rf.maxDepth, [5, 10])    # Tune maximum depth of trees\n              .build())\n\n# Define evaluator\nevaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# TrainValidationSplit for tuning\ntrain_val_split = TrainValidationSplit(estimator=rf_pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=evaluator,\n                                       trainRatio=0.8)\n\n# Train the model with hyperparameter tuning\nrf_model = train_val_split.fit(train_data)\n\n# Get the best model\nbest_rf_model = rf_model.bestModel\n\n# Make predictions on the test data\nrf_predictions = best_rf_model.transform(test_data)\n\n# Evaluate the model\nrf_rmse = evaluator.evaluate(rf_predictions)  # RMSE\nrf_r2 = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(rf_predictions)  # R2\nrf_mae = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(rf_predictions)  # MAE\nrf_mse = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\").evaluate(rf_predictions)  # MSE\n\n# Print metrics\nprint(f\"Random Forest Regressor - RMSE: {rf_rmse}\")\nprint(f\"Random Forest Regressor - R2: {rf_r2}\")\nprint(f\"Random Forest Regressor - MAE: {rf_mae}\")\nprint(f\"Random Forest Regressor - MSE: {rf_mse}\")\n\n"}, {"cell_type": "code", "execution_count": 12, "id": "07237ad2-a05c-4ecd-975c-275bee40a46f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "rf_predictions.write.mode(\"overwrite\").parquet(\"gs://bucket121024/pipeline3/5_RF.parquet\")"}, {"cell_type": "markdown", "id": "2e3b75d8-1b11-45de-b1c2-8ff3797614f6", "metadata": {}, "source": "- **`regParam`**: Regularization parameter (lambda) to prevent overfitting.\n  - Values tested: `[0.1, 0.3]`\n- **`elasticNetParam`**: Mixing parameter to balance L1 (Lasso) and L2 (Ridge) regularization.\n  - Values tested: `[0.0, 0.5]`\n  - `0.0`: Pure L2 (Ridge) regularization.\n  - `0.5`: A mix of L1 and L2 regularization."}, {"cell_type": "code", "execution_count": 25, "id": "7e3a2a4d-c115-4366-b604-41cb837496d7", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 900:=================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Linear Regression - Best RMSE: 2.4394544559764983\nLinear Regression - Best R2: 0.6993895954480251\nLinear Regression - Best MAE: 1.6496203030622447\nLinear Regression - Best MSE: 5.950938042783593\nCPU times: user 540 ms, sys: 111 ms, total: 652 ms\nWall time: 7min 9s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\nlr_pipeline = Pipeline(stages=[assembler, scaler, lr])\n\n\nparam_grid = (ParamGridBuilder()\n              .addGrid(lr.regParam, [0.1, 0.3])\n              .addGrid(lr.elasticNetParam, [0.0, 0.5])\n              .build())\n\n\nrmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n\ntrain_val_split = TrainValidationSplit(estimator=lr_pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=rmse_evaluator,\n                                       trainRatio=0.8)\n\n\nlr_model = train_val_split.fit(train_data)\n\nbest_lr_model = lr_model.bestModel\n\nlr_predictions = best_lr_model.transform(test_data)\n\nlr_rmse = rmse_evaluator.evaluate(lr_predictions)  # RMSE\nlr_r2 = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(lr_predictions)  # R\u00b2\nlr_mae = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(lr_predictions)  # MAE\nlr_mse = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\").evaluate(lr_predictions)  # MSE\n\n# Print all evaluation metrics\nprint(f\"Linear Regression - Best RMSE: {lr_rmse}\")\nprint(f\"Linear Regression - Best R2: {lr_r2}\")\nprint(f\"Linear Regression - Best MAE: {lr_mae}\")\nprint(f\"Linear Regression - Best MSE: {lr_mse}\")\n"}, {"cell_type": "code", "execution_count": 26, "id": "4c64e5bd-c5d5-4aba-9284-7153c3abbda3", "metadata": {"tags": []}, "outputs": [], "source": "\ntrain_data = spark.read.parquet(train)\ntest_data = spark.read.parquet(test)\ntrain_data = train_data.repartition(20)\ntest_data = test_data.repartition(20)\ntrain_data = train_data.sample(withReplacement=False, fraction=0.8)\ntest_data = test_data.sample(withReplacement=False, fraction=0.8)\n"}, {"cell_type": "code", "execution_count": 27, "id": "4c13fc70-b0c8-48d7-83de-f4eb46e5849a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 989:=================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Linear Regression - Best RMSE: 2.439849197930256\nLinear Regression - Best R2: 0.6993260639022114\nLinear Regression - Best MAE: 1.64979592541034\nLinear Regression - Best MSE: 5.952864108640914\nCPU times: user 492 ms, sys: 145 ms, total: 637 ms\nWall time: 6min 3s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\nlr_pipeline = Pipeline(stages=[assembler, scaler, lr])\n\n\nparam_grid = (ParamGridBuilder()\n              .addGrid(lr.regParam, [0.1, 0.3])\n              .addGrid(lr.elasticNetParam, [0.0, 0.5])\n              .build())\n\n\nrmse_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n\ntrain_val_split = TrainValidationSplit(estimator=lr_pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=rmse_evaluator,\n                                       trainRatio=0.8)\n\n\nlr_model = train_val_split.fit(train_data)\n\nbest_lr_model = lr_model.bestModel\n\nlr_predictions = best_lr_model.transform(test_data)\n\nlr_rmse = rmse_evaluator.evaluate(lr_predictions)  # RMSE\nlr_r2 = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(lr_predictions)  # R\u00b2\nlr_mae = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(lr_predictions)  # MAE\nlr_mse = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\").evaluate(lr_predictions)  # MSE\n\n# Print all evaluation metrics\nprint(f\"Linear Regression - Best RMSE: {lr_rmse}\")\nprint(f\"Linear Regression - Best R2: {lr_r2}\")\nprint(f\"Linear Regression - Best MAE: {lr_mae}\")\nprint(f\"Linear Regression - Best MSE: {lr_mse}\")\n"}, {"cell_type": "code", "execution_count": 14, "id": "e4c29770-8c44-4986-ad01-06cff3244a96", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "lr_predictions.write.mode(\"overwrite\").parquet(\"gs://bucket121024/pipeline3/5_LR.parquet\")"}, {"cell_type": "markdown", "id": "976578c0-1dc6-4016-9625-dc5c31e9a857", "metadata": {}, "source": "### Hyperparameter Tuning for Gradient Boosted Trees (GBT)\n\nTo optimize the performance of the Gradient Boosted Trees (GBT) model, a minimal hyperparameter tuning process was implemented using the following key parameters:\n\n1. **`maxDepth`**:\n   - Controls the maximum depth of the trees.\n   - A deeper tree can model more complex relationships but risks overfitting.\n   - Values tested: `[3, 5]`.\n\n2. **`maxIter`**:\n   - Determines the number of boosting iterations.\n   - More iterations allow the model to refine predictions but increase computation time.\n   - Values tested: `[10, 20]`.\n\n3. **`stepSize`**:\n   - Represents the learning rate for gradient boosting.\n   - Smaller step sizes make the model converge more slowly but can improve generalization.\n   - Values tested: `[0.05, 0.1]`.\n\nThe chosen hyperparameter ranges strike a balance between computational efficiency and model performance, ensuring scalability for large datasets.\n"}, {"cell_type": "code", "execution_count": 28, "id": "f8b7f539-4b30-4a42-899a-0b5d123c0f03", "metadata": {"tags": []}, "outputs": [], "source": "train_data = spark.read.parquet(train)\ntest_data = spark.read.parquet(test)\ntrain_data = train_data.repartition(20)\ntest_data = test_data.repartition(20)"}, {"cell_type": "code", "execution_count": 29, "id": "ec0be690-b7ff-417b-8162-ed8a7726ef58", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_785_19 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_11_9 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_11_19 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_827_9 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_827_19 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_11_7 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_785_9 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_785_7 !\n24/12/22 01:02:05 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_827_7 !\n24/12/22 01:02:06 WARN YarnAllocator: Container from a bad node: container_1734808064864_0002_01_000005 on host: cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal. Exit status: 143. Diagnostics: [2024-12-22 01:02:05.692]Container killed on request. Exit code is 143\n[2024-12-22 01:02:05.693]Container exited with a non-zero exit code 143. \n[2024-12-22 01:02:05.693]Killed by external signal\n.\n24/12/22 01:02:06 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1734808064864_0002_01_000005 on host: cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal. Exit status: 143. Diagnostics: [2024-12-22 01:02:05.692]Container killed on request. Exit code is 143\n[2024-12-22 01:02:05.693]Container exited with a non-zero exit code 143. \n[2024-12-22 01:02:05.693]Killed by external signal\n.\n24/12/22 01:02:06 ERROR YarnScheduler: Lost executor 4 on cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal: Container from a bad node: container_1734808064864_0002_01_000005 on host: cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal. Exit status: 143. Diagnostics: [2024-12-22 01:02:05.692]Container killed on request. Exit code is 143\n[2024-12-22 01:02:05.693]Container exited with a non-zero exit code 143. \n[2024-12-22 01:02:05.693]Killed by external signal\n.\n24/12/22 01:02:06 WARN TaskSetManager: Lost task 9.0 in stage 2875.0 (TID 34448) (cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1734808064864_0002_01_000005 on host: cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal. Exit status: 143. Diagnostics: [2024-12-22 01:02:05.692]Container killed on request. Exit code is 143\n[2024-12-22 01:02:05.693]Container exited with a non-zero exit code 143. \n[2024-12-22 01:02:05.693]Killed by external signal\n.\n24/12/22 01:02:06 WARN TaskSetManager: Lost task 5.0 in stage 2875.0 (TID 34444) (cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1734808064864_0002_01_000005 on host: cluster-20f0-w-2.us-central1-c.c.wired-aspect-440122-m9.internal. Exit status: 143. Diagnostics: [2024-12-22 01:02:05.692]Container killed on request. Exit code is 143\n[2024-12-22 01:02:05.693]Container exited with a non-zero exit code 143. \n[2024-12-22 01:02:05.693]Killed by external signal\n.\n[Stage 2883:================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "GBT Regressor - Best RMSE: 2.063421182984908\nGBT Regressor - Best R2: 0.7849228124984564\nGBT Regressor - Best MAE: 1.3436615856728804\nGBT Regressor - Best MSE: 4.2577069783908374\nCPU times: user 4.51 s, sys: 1.09 s, total: 5.61 s\nWall time: 52min 30s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\nfrom pyspark.ml.regression import GBTRegressor\n\n# Initialize GBT Regressor\ngbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\ngbt_pipeline = Pipeline(stages=[assembler, scaler, gbt])\n\n# hyperparameter grid for tuning\nparam_grid = (ParamGridBuilder()\n              .addGrid(gbt.maxDepth, [3, 5]) \n              .addGrid(gbt.maxIter, [10, 20])\n              .addGrid(gbt.stepSize, [0.05, 0.1])\n              .build())\n\nevaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\ntrain_val_split = TrainValidationSplit(estimator=gbt_pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=evaluator,\n                                       trainRatio=0.8)\ngbt_model = train_val_split.fit(train_data)\nbest_gbt_model = gbt_model.bestModel\n\ngbt_predictions = best_gbt_model.transform(test_data)\n\ngbt_rmse = evaluator.evaluate(gbt_predictions)  # RMSE\ngbt_r2 = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(gbt_predictions)  # R\u00b2\ngbt_mae = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(gbt_predictions)  # MAE\ngbt_mse = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\").evaluate(gbt_predictions)  # MSE\n\n# Print evaluation metrics\nprint(f\"GBT Regressor - Best RMSE: {gbt_rmse}\")\nprint(f\"GBT Regressor - Best R2: {gbt_r2}\")\nprint(f\"GBT Regressor - Best MAE: {gbt_mae}\")\nprint(f\"GBT Regressor - Best MSE: {gbt_mse}\")\n"}, {"cell_type": "code", "execution_count": 30, "id": "e508338d-7f41-437c-aa38-e9e7eafe6041", "metadata": {"tags": []}, "outputs": [], "source": "\ntrain_data = spark.read.parquet(train)\ntest_data = spark.read.parquet(test)\ntrain_data = train_data.repartition(20)\ntest_data = test_data.repartition(20)\ntrain_data = train_data.sample(withReplacement=False, fraction=0.8)\ntest_data = test_data.sample(withReplacement=False, fraction=0.8)\n"}, {"cell_type": "code", "execution_count": null, "id": "79247894-2fba-4898-9f76-8ba6216f6b03", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 4777:=============================>                        (11 + 8) / 20]\r"}], "source": "%%time\n\nfrom pyspark.ml.regression import GBTRegressor\n\n# Initialize GBT Regressor\ngbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"demand\")\n\ngbt_pipeline = Pipeline(stages=[assembler, scaler, gbt])\n\n# hyperparameter grid for tuning\nparam_grid = (ParamGridBuilder()\n              .addGrid(gbt.maxDepth, [3, 5]) \n              .addGrid(gbt.maxIter, [10, 20])\n              .addGrid(gbt.stepSize, [0.05, 0.1])\n              .build())\n\nevaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"rmse\")\ntrain_val_split = TrainValidationSplit(estimator=gbt_pipeline,\n                                       estimatorParamMaps=param_grid,\n                                       evaluator=evaluator,\n                                       trainRatio=0.8)\ngbt_model = train_val_split.fit(train_data)\nbest_gbt_model = gbt_model.bestModel\n\ngbt_predictions = best_gbt_model.transform(test_data)\n\ngbt_rmse = evaluator.evaluate(gbt_predictions)  # RMSE\ngbt_r2 = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(gbt_predictions)  # R\u00b2\ngbt_mae = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(gbt_predictions)  # MAE\ngbt_mse = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\").evaluate(gbt_predictions)  # MSE\n\n# Print evaluation metrics\nprint(f\"GBT Regressor - Best RMSE: {gbt_rmse}\")\nprint(f\"GBT Regressor - Best R2: {gbt_r2}\")\nprint(f\"GBT Regressor - Best MAE: {gbt_mae}\")\nprint(f\"GBT Regressor - Best MSE: {gbt_mse}\")\n"}, {"cell_type": "code", "execution_count": null, "id": "9094ec79-4c8c-42d8-98c4-b3de1a3624a4", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}